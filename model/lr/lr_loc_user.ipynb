{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee52034",
   "metadata": {},
   "source": [
    "# TFIDF-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf6a74",
   "metadata": {},
   "source": [
    "# 1、data extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145d1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7890d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filename):\n",
    "    \"\"\"\n",
    "    args: \n",
    "        data: {user_id:{\"text\":text,\"user\":user,\"place_id\":place_id}}\n",
    "     \n",
    "    return:\n",
    "        result: {text: [text1,text2,...],length:[length1,length2,...],label:[rumor or not,...] } \n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as obj:\n",
    "        for line in obj.readlines():\n",
    "            data = json.loads(line)\n",
    "    result = {}\n",
    "    text = []\n",
    "    textlabel = []\n",
    "    location = []\n",
    "    length = []\n",
    "    for user_id in data.keys():\n",
    "        text.append(data[user_id]['text'])\n",
    "        textlabel.append(data[user_id]['place_id']) \n",
    "        length.append(len(data[user_id]['text']))\n",
    "        location.append(data[user_id]['user']['description']+data[user_id]['user']['location'])\n",
    "    result['text'] = text\n",
    "    result['length'] = length\n",
    "    result['label'] = textlabel\n",
    "    result['description'] = location\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9119ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './train_dev_data/0905_1005.txt'\n",
    "train_dev = prepare_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f337e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f393d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just posted a photo @ West End https://t.co/se...</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>🧸🐝🍔😎🐱🖖🏻💅🏻👬🦄🌳🍁🍑🍕🍩☕️🧘🏼‍♂️🎟🎭🎬🎹✈️🛸💉❤️♊️🇦🇺🇯🇵West En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just posted a photo @ Caulfield North, Victori...</td>\n",
       "      <td>2384</td>\n",
       "      <td>3</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WATERCOLOUR ART CLASSES ONLINE  Thursday 9 Sep...</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>Educator researcher Teacher Education, Creativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just posted a photo @ Centennial Parklands htt...</td>\n",
       "      <td>1641</td>\n",
       "      <td>1</td>\n",
       "      <td>Wannabe pro triathlete, lover of good coffee &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just posted a photo @ Richmond Hill Angus http...</td>\n",
       "      <td>264</td>\n",
       "      <td>11</td>\n",
       "      <td>We are a family owned Angus cattle and Southdo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length  label  \\\n",
       "0  Just posted a photo @ West End https://t.co/se...      54      4   \n",
       "1  Just posted a photo @ Caulfield North, Victori...    2384      3   \n",
       "2  WATERCOLOUR ART CLASSES ONLINE  Thursday 9 Sep...     280      1   \n",
       "3  Just posted a photo @ Centennial Parklands htt...    1641      1   \n",
       "4  Just posted a photo @ Richmond Hill Angus http...     264     11   \n",
       "\n",
       "                                         description  \n",
       "0  🧸🐝🍔😎🐱🖖🏻💅🏻👬🦄🌳🍁🍑🍕🍩☕️🧘🏼‍♂️🎟🎭🎬🎹✈️🛸💉❤️♊️🇦🇺🇯🇵West En...  \n",
       "1                               Melbourne, Australia  \n",
       "2  Educator researcher Teacher Education, Creativ...  \n",
       "3  Wannabe pro triathlete, lover of good coffee &...  \n",
       "4  We are a family owned Angus cattle and Southdo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_df = pd.DataFrame(train_dev)\n",
    "train_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7abc6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the train_dev dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_processed = train_dev_df['description']\n",
    "y_processed = train_dev_df['label']\n",
    "x_train,x_dev,y_train,y_dev = train_test_split(x_processed,y_processed,test_size = 0.3,stratify = y_processed,random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b33875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055\n",
      "2132\n"
     ]
    }
   ],
   "source": [
    "print(len(set(x_train)))\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0bc503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132\n",
      "915\n",
      "121     1\n",
      "1473    0\n",
      "1741    4\n",
      "2189    5\n",
      "2666    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_dev))\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f320347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train.iloc[:].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af0bb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f162ca07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_n: 2 features: 10000 score:0.1829\n",
      "max_n: 2 features: 20000 score:0.1764\n",
      "max_n: 2 features: 30000 score:0.1718\n",
      "max_n: 2 features: 40000 score:0.1699\n",
      "max_n: 2 features: 50000 score:0.1699\n",
      "max_n: 2 features: 60000 score:0.1699\n",
      "max_n: 2 features: 70000 score:0.1699\n",
      "max_n: 2 features: 80000 score:0.1699\n",
      "max_n: 2 features: 90000 score:0.1699\n",
      "max_n: 3 features: 10000 score:0.1816\n",
      "max_n: 3 features: 20000 score:0.1784\n",
      "max_n: 3 features: 30000 score:0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyibo06/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_n: 3 features: 40000 score:0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyibo06/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_n: 3 features: 50000 score:0.1657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyibo06/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_n: 3 features: 60000 score:0.1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyibo06/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_n: 3 features: 70000 score:0.1621\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d1f398eab2ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         clf = svm.SVC()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    756\u001b[0m             iprint = [-1, 50, 1, 100, 101][\n\u001b[1;32m    757\u001b[0m                 np.searchsorted(np.array([0, 1, 2, 3]), verbose)]\n\u001b[0;32m--> 758\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    617\u001b[0m                                   **options)\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# LBFGSB is sent 'old-style' bounds, 'new-style' bounds are required by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# approx_derivative and ScalarFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0mnew_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_bound_to_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;31m# check bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_constraints.py\u001b[0m in \u001b[0;36mold_bound_to_new\u001b[0;34m(bounds)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \"\"\"\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# Convert occurrences of None to -inf or inf, and replace occurrences of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "#lr ngram 4,features 10000\n",
    "from sklearn import svm\n",
    "\n",
    "best_score = 0\n",
    "best_clf = None\n",
    "best_tfidf = None\n",
    "for max_n in range(2,4):\n",
    "    for features in range(10000,100000,10000):\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, max_n), max_features=features).fit(x_train.iloc[:].values)\n",
    "        train_tfidf = tfidf.transform(x_train.iloc[:].values)\n",
    "        dev_tfidf = tfidf.transform(x_dev.iloc[:].values)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(train_tfidf, y_train.iloc[:].values)\n",
    "        val_pred = clf.predict(dev_tfidf)\n",
    "        score = f1_score(y_dev.iloc[:].values, val_pred, average='macro')\n",
    "        print('max_n:',max_n,'features:',features,'score:%.4f'%score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_clf = clf\n",
    "            best_max_n = max_n\n",
    "            best_features = features\n",
    "print('best_n:',best_max_n,'best_features:',best_features,'best_score:%.4f'%best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dd0f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_n: 2 features: 1000 score:0.3775\n",
      "max_n: 2 features: 2000 score:0.3596\n",
      "max_n: 2 features: 3000 score:0.3585\n",
      "max_n: 2 features: 4000 score:0.3585\n",
      "max_n: 2 features: 5000 score:0.3585\n",
      "max_n: 2 features: 6000 score:0.3585\n",
      "max_n: 2 features: 7000 score:0.3585\n",
      "max_n: 2 features: 8000 score:0.3585\n",
      "max_n: 2 features: 9000 score:0.3585\n",
      "max_n: 2 features: 10000 score:0.3585\n",
      "max_n: 2 features: 11000 score:0.3585\n",
      "max_n: 2 features: 12000 score:0.3585\n",
      "max_n: 2 features: 13000 score:0.3585\n",
      "max_n: 2 features: 14000 score:0.3585\n",
      "max_n: 2 features: 15000 score:0.3585\n",
      "max_n: 2 features: 16000 score:0.3585\n",
      "max_n: 2 features: 17000 score:0.3585\n",
      "max_n: 2 features: 18000 score:0.3585\n",
      "max_n: 2 features: 19000 score:0.3585\n",
      "best_n: 2 best_features: 1000 best_score:0.3775\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "#lr ngram 4,features 10000\n",
    "from sklearn import svm\n",
    "\n",
    "best_score = 0\n",
    "best_clf = None\n",
    "best_tfidf = None\n",
    "for max_n in range(2,3):\n",
    "    for features in range(1000,20000,1000):\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, max_n), max_features=features).fit(x_train.iloc[:].values)\n",
    "        train_tfidf = tfidf.transform(x_train.iloc[:].values)\n",
    "        dev_tfidf = tfidf.transform(x_dev.iloc[:].values)\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(train_tfidf, y_train.iloc[:].values)\n",
    "        val_pred = clf.predict(dev_tfidf)\n",
    "        score = f1_score(y_dev.iloc[:].values, val_pred, average='macro')\n",
    "        print('max_n:',max_n,'features:',features,'score:%.4f'%score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_clf = clf\n",
    "            best_max_n = max_n\n",
    "            best_features = features\n",
    "print('best_n:',best_max_n,'best_features:',best_features,'best_score:%.4f'%best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00c86254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_n: 2 best_features: 1000 best_score:0.3775\n"
     ]
    }
   ],
   "source": [
    "print('best_n:',best_max_n,'best_features:',best_features,'best_score:%.4f'%best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c77a8b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf-lr_ngram5_features4000_score0.40955266149151254.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# store the model\n",
    "joblib.dump(best_clf, 'tfidf-lr_ngram{}_features{}_score{}.pkl'.format(best_max_n,best_features,best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e9e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_n = 2\n",
    "best_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "585c2cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score:0.3821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        20\n",
      "           0       0.60      0.38      0.46        69\n",
      "           1       0.41      0.88      0.56       214\n",
      "           2       0.69      0.29      0.41        38\n",
      "           3       0.71      0.64      0.67       187\n",
      "           4       0.78      0.57      0.66        79\n",
      "           5       0.65      0.41      0.50        95\n",
      "           6       1.00      0.15      0.27        13\n",
      "           7       0.74      0.61      0.67        51\n",
      "           8       0.74      0.52      0.61        60\n",
      "           9       0.25      0.05      0.08        22\n",
      "          10       0.50      0.29      0.36         7\n",
      "          11       0.86      0.55      0.67        11\n",
      "          12       0.50      0.05      0.08        22\n",
      "          13       0.00      0.00      0.00         6\n",
      "          14       0.88      0.35      0.50        20\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       915\n",
      "   macro avg       0.55      0.34      0.38       915\n",
      "weighted avg       0.60      0.56      0.54       915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyibo06/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangyibo06/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangyibo06/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,best_max_n+1), max_features=best_features).fit(x_train.iloc[:].values)\n",
    "train_tfidf = tfidf.transform(x_train.iloc[:].values)\n",
    "dev_tfidf = tfidf.transform(x_dev.iloc[:].values)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_tfidf, y_train.iloc[:].values)\n",
    "\n",
    "val_pred = clf.predict(dev_tfidf)\n",
    "score = f1_score(y_dev.iloc[:].values, val_pred, average='macro')\n",
    "\n",
    "print('best_score:%.4f'%score)\n",
    "print(metrics.classification_report(y_dev.iloc[:].values,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4022b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare for the test data\n",
    "def prepare_test(filename):\n",
    "    \"\"\"\n",
    "    args: \n",
    "        data: {user_id:{\"text\":text,\"user\":user,\"place_id\":place_id}}\n",
    "     \n",
    "    return:\n",
    "        result: {text: [text1,text2,...],length:[length1,length2,...],label:[rumor or not,...] } \n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as obj:\n",
    "        for line in obj.readlines():\n",
    "            data = json.loads(line)\n",
    "    result = {}\n",
    "    text = []\n",
    "    location = []\n",
    "    length = []\n",
    "    user_ids = []\n",
    "    for user_id in data.keys():\n",
    "        user_ids.append(user_id)\n",
    "        text.append(data[user_id]['text'])\n",
    "        length.append(len(data[user_id]['text']))\n",
    "        location.append(data[user_id]['location'])\n",
    "    result['user_id'] = user_ids\n",
    "    result['text'] = text\n",
    "    result['length'] = length\n",
    "    result['location'] = location\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae4041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './test_data/0905.txt'\n",
    "test = prepare_test(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3236ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276090111</td>\n",
       "      <td>@aVoice2bHrd You know how I am 😭I cut family o...</td>\n",
       "      <td>138</td>\n",
       "      <td>West Coast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499908182</td>\n",
       "      <td>@AusAndy Most people probably have one now fro...</td>\n",
       "      <td>187</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952211163</td>\n",
       "      <td>@anassilvvaa Bora@anassilvvaa Se envolver dinh...</td>\n",
       "      <td>1948</td>\n",
       "      <td>Invicta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>788532504626012160</td>\n",
       "      <td>@60Mins Will this program be replayed?Is last ...</td>\n",
       "      <td>1284</td>\n",
       "      <td>Newcastle, New South Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1459159765</td>\n",
       "      <td>Breaking news: emergency COVID laws applying t...</td>\n",
       "      <td>133</td>\n",
       "      <td>Fortitude Valley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id                                               text  \\\n",
       "0           276090111  @aVoice2bHrd You know how I am 😭I cut family o...   \n",
       "1          1499908182  @AusAndy Most people probably have one now fro...   \n",
       "2          1952211163  @anassilvvaa Bora@anassilvvaa Se envolver dinh...   \n",
       "3  788532504626012160  @60Mins Will this program be replayed?Is last ...   \n",
       "4          1459159765  Breaking news: emergency COVID laws applying t...   \n",
       "\n",
       "   length                    location  \n",
       "0     138                  West Coast  \n",
       "1     187     Sydney, New South Wales  \n",
       "2    1948                     Invicta  \n",
       "3    1284  Newcastle, New South Wales  \n",
       "4     133            Fortitude Valley  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b6704d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1 ... 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,best_max_n+1), max_features=best_features).fit(x_train.iloc[:].values)\n",
    "# train_tfidf = tfidf.transform(x_train.iloc[:].values)\n",
    "# dev_tfidf = tfidf.transform(x_dev.iloc[:].values)\n",
    "test_tfidf = tfidf.transform(test_df['text'].iloc[:].values)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_tfidf, y_train.iloc[:].values)\n",
    "\n",
    "val_pred = clf.predict(test_tfidf)\n",
    "print(val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d905d1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>location</th>\n",
       "      <th>predict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276090111</td>\n",
       "      <td>@aVoice2bHrd You know how I am 😭I cut family o...</td>\n",
       "      <td>138</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499908182</td>\n",
       "      <td>@AusAndy Most people probably have one now fro...</td>\n",
       "      <td>187</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952211163</td>\n",
       "      <td>@anassilvvaa Bora@anassilvvaa Se envolver dinh...</td>\n",
       "      <td>1948</td>\n",
       "      <td>Invicta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>788532504626012160</td>\n",
       "      <td>@60Mins Will this program be replayed?Is last ...</td>\n",
       "      <td>1284</td>\n",
       "      <td>Newcastle, New South Wales</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1459159765</td>\n",
       "      <td>Breaking news: emergency COVID laws applying t...</td>\n",
       "      <td>133</td>\n",
       "      <td>Fortitude Valley</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id                                               text  \\\n",
       "0           276090111  @aVoice2bHrd You know how I am 😭I cut family o...   \n",
       "1          1499908182  @AusAndy Most people probably have one now fro...   \n",
       "2          1952211163  @anassilvvaa Bora@anassilvvaa Se envolver dinh...   \n",
       "3  788532504626012160  @60Mins Will this program be replayed?Is last ...   \n",
       "4          1459159765  Breaking news: emergency COVID laws applying t...   \n",
       "\n",
       "   length                    location  predict_label  \n",
       "0     138                  West Coast              1  \n",
       "1     187     Sydney, New South Wales              3  \n",
       "2    1948                     Invicta              1  \n",
       "3    1284  Newcastle, New South Wales              3  \n",
       "4     133            Fortitude Valley              1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construct the test output file\n",
    "test_df['predict_label'] = val_pred\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe3e2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write predictions to json\n",
    "# from collection import OrderedDict\n",
    "def write2json(filename,dataframe):\n",
    "    \"\"\"\n",
    "    args: \n",
    "        filename: the filename of the predicted data label file\n",
    "        dataframe: the dataframe of the predicted data\n",
    "    return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    file_cnt = 0\n",
    "    new_dict = {}\n",
    "    with open(filename, 'w') as file:\n",
    "        \n",
    "        for index,row in dataframe.iterrows():\n",
    "            new_dict['id'] = row['user_id']\n",
    "            new_dict['place_id'] = row['predict_label']\n",
    "        \n",
    "            json_line = json.dumps(new_dict)\n",
    "            file.write(json_line+'\\n')\n",
    "            file_cnt += 1\n",
    "            if file_cnt % 100 == 0:\n",
    "                print('file:'+str(file_cnt))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d3db04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:100\n",
      "file:200\n",
      "file:300\n",
      "file:400\n",
      "file:500\n",
      "file:600\n",
      "file:700\n",
      "file:800\n",
      "file:900\n",
      "file:1000\n",
      "file:1100\n",
      "file:1200\n",
      "file:1300\n",
      "file:1400\n",
      "file:1500\n",
      "file:1600\n",
      "file:1700\n",
      "file:1800\n",
      "file:1900\n",
      "file:2000\n",
      "file:2100\n",
      "file:2200\n",
      "file:2300\n",
      "file:2400\n",
      "file:2500\n",
      "file:2600\n",
      "file:2700\n",
      "file:2800\n",
      "file:2900\n",
      "file:3000\n",
      "file:3100\n",
      "file:3200\n",
      "file:3300\n",
      "file:3400\n",
      "file:3500\n",
      "file:3600\n",
      "file:3700\n",
      "file:3800\n",
      "file:3900\n",
      "file:4000\n",
      "file:4100\n",
      "file:4200\n",
      "file:4300\n",
      "file:4400\n",
      "file:4500\n",
      "file:4600\n",
      "file:4700\n",
      "file:4800\n",
      "file:4900\n",
      "file:5000\n",
      "file:5100\n",
      "file:5200\n",
      "file:5300\n",
      "file:5400\n",
      "file:5500\n",
      "file:5600\n",
      "file:5700\n",
      "file:5800\n",
      "file:5900\n",
      "file:6000\n",
      "file:6100\n",
      "file:6200\n",
      "file:6300\n",
      "file:6400\n",
      "file:6500\n",
      "file:6600\n",
      "file:6700\n",
      "file:6800\n",
      "file:6900\n",
      "file:7000\n",
      "file:7100\n",
      "file:7200\n",
      "file:7300\n",
      "file:7400\n",
      "file:7500\n",
      "file:7600\n",
      "file:7700\n",
      "file:7800\n",
      "file:7900\n",
      "file:8000\n",
      "file:8100\n",
      "file:8200\n",
      "file:8300\n",
      "file:8400\n",
      "file:8500\n",
      "file:8600\n",
      "file:8700\n",
      "file:8800\n",
      "file:8900\n",
      "file:9000\n",
      "file:9100\n",
      "file:9200\n",
      "file:9300\n",
      "file:9400\n",
      "file:9500\n",
      "file:9600\n",
      "file:9700\n",
      "file:9800\n",
      "file:9900\n",
      "file:10000\n",
      "file:10100\n",
      "file:10200\n",
      "file:10300\n",
      "file:10400\n",
      "file:10500\n",
      "file:10600\n",
      "file:10700\n",
      "file:10800\n",
      "file:10900\n",
      "file:11000\n",
      "file:11100\n",
      "file:11200\n",
      "file:11300\n",
      "file:11400\n",
      "file:11500\n",
      "file:11600\n",
      "file:11700\n",
      "file:11800\n",
      "file:11900\n",
      "file:12000\n",
      "file:12100\n",
      "file:12200\n",
      "file:12300\n",
      "file:12400\n",
      "file:12500\n",
      "file:12600\n",
      "file:12700\n",
      "file:12800\n",
      "file:12900\n",
      "file:13000\n",
      "file:13100\n",
      "file:13200\n",
      "file:13300\n",
      "file:13400\n",
      "file:13500\n",
      "file:13600\n",
      "file:13700\n",
      "file:13800\n",
      "file:13900\n",
      "file:14000\n",
      "file:14100\n",
      "file:14200\n",
      "file:14300\n",
      "file:14400\n",
      "file:14500\n",
      "file:14600\n",
      "file:14700\n",
      "file:14800\n",
      "file:14900\n",
      "file:15000\n",
      "file:15100\n",
      "file:15200\n",
      "file:15300\n",
      "file:15400\n",
      "file:15500\n",
      "file:15600\n",
      "file:15700\n",
      "file:15800\n",
      "file:15900\n",
      "file:16000\n",
      "file:16100\n",
      "file:16200\n",
      "file:16300\n",
      "file:16400\n",
      "file:16500\n",
      "file:16600\n",
      "file:16700\n",
      "file:16800\n",
      "file:16900\n",
      "file:17000\n",
      "file:17100\n",
      "file:17200\n",
      "file:17300\n",
      "file:17400\n",
      "file:17500\n",
      "file:17600\n",
      "file:17700\n",
      "file:17800\n",
      "file:17900\n",
      "file:18000\n",
      "file:18100\n",
      "file:18200\n",
      "file:18300\n",
      "file:18400\n",
      "file:18500\n",
      "file:18600\n",
      "file:18700\n",
      "file:18800\n",
      "file:18900\n",
      "file:19000\n",
      "file:19100\n",
      "file:19200\n",
      "file:19300\n",
      "file:19400\n",
      "file:19500\n",
      "file:19600\n",
      "file:19700\n",
      "file:19800\n",
      "file:19900\n",
      "file:20000\n",
      "file:20100\n",
      "file:20200\n",
      "file:20300\n",
      "file:20400\n",
      "file:20500\n",
      "file:20600\n",
      "file:20700\n",
      "file:20800\n",
      "file:20900\n",
      "file:21000\n",
      "file:21100\n",
      "file:21200\n",
      "file:21300\n",
      "file:21400\n",
      "file:21500\n",
      "file:21600\n",
      "file:21700\n",
      "file:21800\n",
      "file:21900\n",
      "file:22000\n",
      "file:22100\n",
      "file:22200\n",
      "file:22300\n",
      "file:22400\n",
      "file:22500\n",
      "file:22600\n",
      "file:22700\n",
      "file:22800\n",
      "file:22900\n",
      "file:23000\n",
      "file:23100\n",
      "file:23200\n",
      "file:23300\n",
      "file:23400\n",
      "file:23500\n",
      "file:23600\n",
      "file:23700\n",
      "file:23800\n",
      "file:23900\n",
      "file:24000\n",
      "file:24100\n",
      "file:24200\n",
      "file:24300\n",
      "file:24400\n",
      "file:24500\n",
      "file:24600\n",
      "file:24700\n",
      "file:24800\n",
      "file:24900\n",
      "file:25000\n",
      "file:25100\n",
      "file:25200\n",
      "file:25300\n",
      "file:25400\n",
      "file:25500\n",
      "file:25600\n",
      "file:25700\n",
      "file:25800\n",
      "file:25900\n",
      "file:26000\n",
      "file:26100\n",
      "file:26200\n",
      "file:26300\n",
      "file:26400\n",
      "file:26500\n",
      "file:26600\n",
      "file:26700\n",
      "file:26800\n",
      "file:26900\n",
      "file:27000\n",
      "file:27100\n",
      "file:27200\n",
      "file:27300\n",
      "file:27400\n",
      "file:27500\n",
      "file:27600\n",
      "file:27700\n",
      "file:27800\n",
      "file:27900\n",
      "file:28000\n",
      "file:28100\n",
      "file:28200\n",
      "file:28300\n",
      "file:28400\n",
      "file:28500\n",
      "file:28600\n",
      "file:28700\n",
      "file:28800\n",
      "file:28900\n",
      "file:29000\n",
      "file:29100\n",
      "file:29200\n",
      "file:29300\n",
      "file:29400\n",
      "file:29500\n",
      "file:29600\n",
      "file:29700\n",
      "file:29800\n",
      "file:29900\n",
      "file:30000\n",
      "file:30100\n",
      "file:30200\n",
      "file:30300\n",
      "file:30400\n",
      "file:30500\n",
      "file:30600\n",
      "file:30700\n",
      "file:30800\n",
      "file:30900\n",
      "file:31000\n",
      "file:31100\n",
      "file:31200\n",
      "file:31300\n",
      "file:31400\n",
      "file:31500\n",
      "file:31600\n",
      "file:31700\n",
      "file:31800\n",
      "file:31900\n",
      "file:32000\n",
      "file:32100\n",
      "file:32200\n",
      "file:32300\n",
      "file:32400\n",
      "file:32500\n",
      "file:32600\n",
      "file:32700\n",
      "file:32800\n",
      "file:32900\n",
      "file:33000\n",
      "file:33100\n",
      "file:33200\n",
      "file:33300\n",
      "file:33400\n",
      "file:33500\n",
      "file:33600\n",
      "file:33700\n",
      "file:33800\n",
      "file:33900\n",
      "file:34000\n",
      "file:34100\n",
      "file:34200\n",
      "file:34300\n",
      "file:34400\n",
      "file:34500\n",
      "file:34600\n",
      "file:34700\n",
      "file:34800\n",
      "file:34900\n",
      "file:35000\n",
      "file:35100\n",
      "file:35200\n",
      "file:35300\n",
      "file:35400\n",
      "file:35500\n",
      "file:35600\n",
      "file:35700\n",
      "file:35800\n",
      "file:35900\n",
      "file:36000\n",
      "file:36100\n",
      "file:36200\n",
      "file:36300\n",
      "file:36400\n",
      "file:36500\n",
      "file:36600\n",
      "file:36700\n",
      "file:36800\n",
      "file:36900\n",
      "file:37000\n",
      "file:37100\n",
      "file:37200\n",
      "file:37300\n",
      "file:37400\n",
      "file:37500\n",
      "file:37600\n",
      "file:37700\n",
      "file:37800\n",
      "file:37900\n",
      "file:38000\n",
      "file:38100\n",
      "file:38200\n",
      "file:38300\n",
      "file:38400\n",
      "file:38500\n",
      "file:38600\n",
      "file:38700\n",
      "file:38800\n",
      "file:38900\n",
      "file:39000\n",
      "file:39100\n",
      "file:39200\n",
      "file:39300\n",
      "file:39400\n",
      "file:39500\n",
      "file:39600\n",
      "file:39700\n",
      "file:39800\n",
      "file:39900\n",
      "file:40000\n",
      "file:40100\n",
      "file:40200\n",
      "file:40300\n",
      "file:40400\n",
      "file:40500\n",
      "file:40600\n",
      "file:40700\n",
      "file:40800\n",
      "file:40900\n",
      "file:41000\n",
      "file:41100\n",
      "file:41200\n",
      "file:41300\n",
      "file:41400\n",
      "file:41500\n",
      "file:41600\n",
      "file:41700\n",
      "file:41800\n",
      "file:41900\n",
      "file:42000\n",
      "file:42100\n",
      "file:42200\n",
      "file:42300\n",
      "file:42400\n",
      "file:42500\n",
      "file:42600\n",
      "file:42700\n",
      "file:42800\n",
      "file:42900\n",
      "file:43000\n",
      "file:43100\n",
      "file:43200\n",
      "file:43300\n",
      "file:43400\n",
      "file:43500\n",
      "file:43600\n",
      "file:43700\n",
      "file:43800\n",
      "file:43900\n",
      "file:44000\n",
      "file:44100\n",
      "file:44200\n",
      "file:44300\n",
      "file:44400\n",
      "file:44500\n",
      "file:44600\n",
      "file:44700\n",
      "file:44800\n",
      "file:44900\n",
      "file:45000\n",
      "file:45100\n",
      "file:45200\n",
      "file:45300\n",
      "file:45400\n",
      "file:45500\n",
      "file:45600\n",
      "file:45700\n",
      "file:45800\n",
      "file:45900\n",
      "file:46000\n",
      "file:46100\n",
      "file:46200\n",
      "file:46300\n",
      "file:46400\n",
      "file:46500\n",
      "file:46600\n",
      "file:46700\n",
      "file:46800\n",
      "file:46900\n",
      "file:47000\n",
      "file:47100\n",
      "file:47200\n",
      "file:47300\n",
      "file:47400\n",
      "file:47500\n",
      "file:47600\n",
      "file:47700\n",
      "file:47800\n",
      "file:47900\n",
      "file:48000\n",
      "file:48100\n",
      "file:48200\n",
      "file:48300\n",
      "file:48400\n",
      "file:48500\n",
      "file:48600\n",
      "file:48700\n",
      "file:48800\n",
      "file:48900\n",
      "file:49000\n",
      "file:49100\n",
      "file:49200\n",
      "file:49300\n",
      "file:49400\n",
      "file:49500\n",
      "file:49600\n",
      "file:49700\n",
      "file:49800\n",
      "file:49900\n",
      "file:50000\n",
      "file:50100\n",
      "file:50200\n",
      "file:50300\n",
      "file:50400\n",
      "file:50500\n",
      "file:50600\n",
      "file:50700\n",
      "file:50800\n",
      "file:50900\n",
      "file:51000\n",
      "file:51100\n",
      "file:51200\n",
      "file:51300\n",
      "file:51400\n",
      "file:51500\n",
      "file:51600\n",
      "file:51700\n",
      "file:51800\n",
      "file:51900\n",
      "file:52000\n",
      "file:52100\n",
      "file:52200\n",
      "file:52300\n",
      "file:52400\n",
      "file:52500\n",
      "file:52600\n",
      "file:52700\n",
      "file:52800\n",
      "file:52900\n",
      "file:53000\n",
      "file:53100\n",
      "file:53200\n",
      "file:53300\n",
      "file:53400\n",
      "file:53500\n",
      "file:53600\n",
      "file:53700\n",
      "file:53800\n",
      "file:53900\n",
      "file:54000\n",
      "file:54100\n",
      "file:54200\n",
      "file:54300\n",
      "file:54400\n",
      "file:54500\n",
      "file:54600\n",
      "file:54700\n",
      "file:54800\n",
      "file:54900\n",
      "file:55000\n",
      "file:55100\n",
      "file:55200\n",
      "file:55300\n",
      "file:55400\n",
      "file:55500\n",
      "file:55600\n",
      "file:55700\n",
      "file:55800\n",
      "file:55900\n",
      "file:56000\n",
      "file:56100\n",
      "file:56200\n",
      "file:56300\n",
      "file:56400\n",
      "file:56500\n",
      "file:56600\n",
      "file:56700\n",
      "file:56800\n",
      "file:56900\n",
      "file:57000\n",
      "file:57100\n",
      "file:57200\n",
      "file:57300\n",
      "file:57400\n",
      "file:57500\n",
      "file:57600\n",
      "file:57700\n",
      "file:57800\n",
      "file:57900\n",
      "file:58000\n",
      "file:58100\n",
      "file:58200\n",
      "file:58300\n",
      "file:58400\n",
      "file:58500\n",
      "file:58600\n",
      "file:58700\n",
      "file:58800\n",
      "file:58900\n",
      "file:59000\n",
      "file:59100\n",
      "file:59200\n",
      "file:59300\n",
      "file:59400\n",
      "file:59500\n",
      "file:59600\n",
      "file:59700\n",
      "file:59800\n",
      "file:59900\n",
      "file:60000\n",
      "file:60100\n",
      "file:60200\n",
      "file:60300\n",
      "file:60400\n",
      "file:60500\n",
      "file:60600\n",
      "file:60700\n",
      "file:60800\n",
      "file:60900\n",
      "file:61000\n",
      "file:61100\n",
      "file:61200\n",
      "file:61300\n",
      "file:61400\n",
      "file:61500\n",
      "file:61600\n",
      "file:61700\n",
      "file:61800\n",
      "file:61900\n",
      "file:62000\n"
     ]
    }
   ],
   "source": [
    "write2json('./ml_predict/lr/lr_0905_v5.json',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473a50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
